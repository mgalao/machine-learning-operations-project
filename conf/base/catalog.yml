# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html


fraud_raw_data:
  type: pandas.CSVDataset
  filepath: data/01_raw/data_v1.csv
  load_args:
    sep: ','

ingested_data:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/ingested_data.csv

ref_data:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/ref_data.csv

ana_data:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/ana_data.csv

reporting_data_train:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: json.JSONDataset
    filepath: data/08_reporting/reporting_data_train.json

manual_tests_results:
  type: pandas.CSVDataset
  filepath: data/08_reporting/manual_tests_results.csv

industry_profiling_results:
  type: pandas.CSVDataset
  filepath: data/08_reporting/industry_profiling_results.csv

psi_scores:
  type: pandas.CSVDataset
  filepath: data/08_reporting/psi_scores.csv

pca_psi_scores:
  type: pandas.CSVDataset
  filepath: data/08_reporting/pca_psi_scores.csv

nannyml_drift:
  type: pandas.CSVDataset
  filepath: data/08_reporting/nannyml_drift.csv
  
drifted_features:
  type: kedro_datasets.json.JSONDataset
  filepath: data/08_reporting/drifted_features.json

preprocessed_training_data:
  type: pandas.CSVDataset
  filepath: data/03_primary/preprocessed_train_data.csv

preprocessed_batch_data:
  type: pandas.CSVDataset
  filepath: data/03_primary/preprocessed_batch_data.csv

# encoder_transform:
#   type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
#   dataset:
#     type: pickle.PickleDataset
#     filepath: data/04_feature/encoder.pkl

feature_engineering_params:
  type: pickle.PickleDataset
  filepath: data/04_feature/feature_engineering_params.pkl

X_train_data:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_train.csv

y_train_data:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_train.csv


X_test_data:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_test.csv

y_test_data:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_test.csv 

production_columns:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: pickle.PickleDataset
    filepath: data/06_models/production_cols.pkl

feature_importance_plot:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: matplotlib.MatplotlibWriter
    filepath: data/08_reporting/feature_importance_plot.png

best_columns:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: pickle.PickleDataset
    filepath: data/06_models/best_cols.pkl

production_model:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: pickle.PickleDataset
    filepath: data/06_models/production_model.pkl

production_model_metrics:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: json.JSONDataset
    filepath: data/08_reporting/production_model_metrics.json

drift_result:
  type: pandas.CSVDataset
  filepath: data/08_reporting/drift_result.csv


output_plot:
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataset
  dataset:
    type: matplotlib.MatplotlibWriter
    filepath: data/08_reporting/shap_plot.png