{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c949336b",
   "metadata": {},
   "source": [
    "# Machine Learning Operations - Data Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa73efd",
   "metadata": {},
   "source": [
    "This notebook was developed by:\n",
    "\n",
    "- Bruna Simões (20240491)\n",
    "- Daniel Caridade (20211588)\n",
    "- Leonardo Di Caterina (20240485)\n",
    "- Marco Galão (r20201545)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00083d4",
   "metadata": {},
   "source": [
    "# 1. Libraries Importation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c8258",
   "metadata": {},
   "source": [
    "__`Step 1`__ Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4d0cea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\notebooks\\utils.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdifflib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_close_matches\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpx\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51240888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from the GitHub repository\n",
    "# Path of project root\n",
    "project_root = Path().resolve().parents[1]\n",
    "\n",
    "# Add the project root directory to Python's module search path\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28cdf90",
   "metadata": {},
   "source": [
    "# 2. Data Integration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51cb07",
   "metadata": {},
   "source": [
    "__`Step 2`__ Importing the dataset into the notebook, ignoring the first columns as it does not contain relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec99b3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>merch_zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-04 11:57:04</td>\n",
       "      <td>4586260469584</td>\n",
       "      <td>fraud_Kerluke Inc</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>5.96</td>\n",
       "      <td>Melody</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>F</td>\n",
       "      <td>0362 Anderson Wall</td>\n",
       "      <td>Mound City</td>\n",
       "      <td>...</td>\n",
       "      <td>-95.2138</td>\n",
       "      <td>1631</td>\n",
       "      <td>Architect</td>\n",
       "      <td>1953-01-20</td>\n",
       "      <td>3d21bce7967838c3988cfe0f7fca878a</td>\n",
       "      <td>1336132624</td>\n",
       "      <td>41.024651</td>\n",
       "      <td>-94.428240</td>\n",
       "      <td>0</td>\n",
       "      <td>50842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-14 08:55:21</td>\n",
       "      <td>4900628639996</td>\n",
       "      <td>fraud_Rempel PLC</td>\n",
       "      <td>grocery_net</td>\n",
       "      <td>70.66</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>M</td>\n",
       "      <td>094 Owens Underpass</td>\n",
       "      <td>Norwalk</td>\n",
       "      <td>...</td>\n",
       "      <td>-118.0818</td>\n",
       "      <td>105549</td>\n",
       "      <td>Firefighter</td>\n",
       "      <td>1973-09-22</td>\n",
       "      <td>fda7712b4bbcaab36afded37ab55047f</td>\n",
       "      <td>1355475321</td>\n",
       "      <td>33.808771</td>\n",
       "      <td>-118.031888</td>\n",
       "      <td>0</td>\n",
       "      <td>90630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-30 05:21:33</td>\n",
       "      <td>676118385837</td>\n",
       "      <td>fraud_Rodriguez Group</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>50.92</td>\n",
       "      <td>Katelyn</td>\n",
       "      <td>Wise</td>\n",
       "      <td>F</td>\n",
       "      <td>674 Maureen Summit Apt. 276</td>\n",
       "      <td>Scotts Mills</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.6187</td>\n",
       "      <td>1252</td>\n",
       "      <td>Engineer, petroleum</td>\n",
       "      <td>1937-02-06</td>\n",
       "      <td>59161e0002642934974c1ae98bfa1f55</td>\n",
       "      <td>1333084893</td>\n",
       "      <td>44.561034</td>\n",
       "      <td>-123.281803</td>\n",
       "      <td>0</td>\n",
       "      <td>97331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-09-19 07:09:46</td>\n",
       "      <td>3596357274378601</td>\n",
       "      <td>fraud_Doyle Ltd</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>71.68</td>\n",
       "      <td>David</td>\n",
       "      <td>Everett</td>\n",
       "      <td>M</td>\n",
       "      <td>4138 David Fall</td>\n",
       "      <td>Morrisdale</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.2357</td>\n",
       "      <td>3688</td>\n",
       "      <td>Advice worker</td>\n",
       "      <td>1973-05-27</td>\n",
       "      <td>f487a7098c0bd4d45f710be1745c4acb</td>\n",
       "      <td>1348038586</td>\n",
       "      <td>41.612825</td>\n",
       "      <td>-78.316893</td>\n",
       "      <td>0</td>\n",
       "      <td>15834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-04 20:37:44</td>\n",
       "      <td>6011542681743618</td>\n",
       "      <td>fraud_Leffler-Goldner</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>29.17</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Hall</td>\n",
       "      <td>F</td>\n",
       "      <td>8851 Reese Neck</td>\n",
       "      <td>Basye</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.7776</td>\n",
       "      <td>863</td>\n",
       "      <td>Engineer, mining</td>\n",
       "      <td>1972-08-09</td>\n",
       "      <td>c2ed76f03cce8a6b362729a5a23f01c2</td>\n",
       "      <td>1328387864</td>\n",
       "      <td>39.387521</td>\n",
       "      <td>-79.674956</td>\n",
       "      <td>0</td>\n",
       "      <td>26444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90762</th>\n",
       "      <td>2019-05-03 01:50:55</td>\n",
       "      <td>4861310130652566408</td>\n",
       "      <td>fraud_Thiel PLC</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>410.37</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>Cruz</td>\n",
       "      <td>F</td>\n",
       "      <td>65417 Walsh Radial Suite 691</td>\n",
       "      <td>Saint Amant</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.8435</td>\n",
       "      <td>10076</td>\n",
       "      <td>Surveyor, rural practice</td>\n",
       "      <td>1977-12-16</td>\n",
       "      <td>14b94dc8026970fae77db1deb747f35f</td>\n",
       "      <td>1336009855</td>\n",
       "      <td>30.152101</td>\n",
       "      <td>-90.420021</td>\n",
       "      <td>0</td>\n",
       "      <td>70068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90763</th>\n",
       "      <td>2020-03-26 22:03:48</td>\n",
       "      <td>4560004149983868183</td>\n",
       "      <td>fraud_Kihn, Brakus and Goyette</td>\n",
       "      <td>personal_care</td>\n",
       "      <td>38.94</td>\n",
       "      <td>Stacy</td>\n",
       "      <td>Villegas</td>\n",
       "      <td>F</td>\n",
       "      <td>20581 Pena Walks</td>\n",
       "      <td>Colorado Springs</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.6556</td>\n",
       "      <td>525713</td>\n",
       "      <td>Museum/gallery exhibitions officer</td>\n",
       "      <td>1992-05-09</td>\n",
       "      <td>f93f924d08a19064ec37de7a69cf8e4b</td>\n",
       "      <td>1364335428</td>\n",
       "      <td>38.648246</td>\n",
       "      <td>-104.969889</td>\n",
       "      <td>0</td>\n",
       "      <td>80926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90764</th>\n",
       "      <td>2019-02-16 14:20:54</td>\n",
       "      <td>378904938837132</td>\n",
       "      <td>fraud_Gerhold LLC</td>\n",
       "      <td>home</td>\n",
       "      <td>29.43</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Zimmerman</td>\n",
       "      <td>F</td>\n",
       "      <td>3595 Susan Island Suite 063</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>...</td>\n",
       "      <td>-98.7388</td>\n",
       "      <td>1675</td>\n",
       "      <td>Barrister</td>\n",
       "      <td>1986-05-01</td>\n",
       "      <td>12177fa4ce00fc361366c28e0af96b81</td>\n",
       "      <td>1329402054</td>\n",
       "      <td>35.110496</td>\n",
       "      <td>-98.246154</td>\n",
       "      <td>0</td>\n",
       "      <td>73005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90765</th>\n",
       "      <td>2019-06-24 14:53:14</td>\n",
       "      <td>4155021259183870</td>\n",
       "      <td>fraud_Stark-Batz</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>3.49</td>\n",
       "      <td>Renee</td>\n",
       "      <td>Parrish</td>\n",
       "      <td>F</td>\n",
       "      <td>174 Jennifer Meadow Apt. 467</td>\n",
       "      <td>Mountain Park</td>\n",
       "      <td>...</td>\n",
       "      <td>-98.9591</td>\n",
       "      <td>540</td>\n",
       "      <td>Research scientist (life sciences)</td>\n",
       "      <td>1983-10-12</td>\n",
       "      <td>4a248f9b8268ba53241625b4af2a271c</td>\n",
       "      <td>1340549594</td>\n",
       "      <td>35.135938</td>\n",
       "      <td>-98.112255</td>\n",
       "      <td>0</td>\n",
       "      <td>73092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90766</th>\n",
       "      <td>2019-06-22 17:21:39</td>\n",
       "      <td>4155021259183870</td>\n",
       "      <td>fraud_Streich, Rolfson and Wilderman</td>\n",
       "      <td>kids_pets</td>\n",
       "      <td>104.23</td>\n",
       "      <td>Renee</td>\n",
       "      <td>Parrish</td>\n",
       "      <td>F</td>\n",
       "      <td>174 Jennifer Meadow Apt. 467</td>\n",
       "      <td>Mountain Park</td>\n",
       "      <td>...</td>\n",
       "      <td>-98.9591</td>\n",
       "      <td>540</td>\n",
       "      <td>Research scientist (life sciences)</td>\n",
       "      <td>1983-10-12</td>\n",
       "      <td>9e73bbda29bc0568cbcf48975a2e1372</td>\n",
       "      <td>1340385699</td>\n",
       "      <td>34.624869</td>\n",
       "      <td>-99.008428</td>\n",
       "      <td>0</td>\n",
       "      <td>73566.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90767 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trans_date_trans_time               cc_num  \\\n",
       "0       2019-05-04 11:57:04        4586260469584   \n",
       "1       2019-12-14 08:55:21        4900628639996   \n",
       "2       2019-03-30 05:21:33         676118385837   \n",
       "3       2019-09-19 07:09:46     3596357274378601   \n",
       "4       2019-02-04 20:37:44     6011542681743618   \n",
       "...                     ...                  ...   \n",
       "90762   2019-05-03 01:50:55  4861310130652566408   \n",
       "90763   2020-03-26 22:03:48  4560004149983868183   \n",
       "90764   2019-02-16 14:20:54      378904938837132   \n",
       "90765   2019-06-24 14:53:14     4155021259183870   \n",
       "90766   2019-06-22 17:21:39     4155021259183870   \n",
       "\n",
       "                                   merchant       category     amt    first  \\\n",
       "0                         fraud_Kerluke Inc       misc_net    5.96   Melody   \n",
       "1                          fraud_Rempel PLC    grocery_net   70.66  Michael   \n",
       "2                     fraud_Rodriguez Group  gas_transport   50.92  Katelyn   \n",
       "3                           fraud_Doyle Ltd    grocery_pos   71.68    David   \n",
       "4                     fraud_Leffler-Goldner  personal_care   29.17    Emily   \n",
       "...                                     ...            ...     ...      ...   \n",
       "90762                       fraud_Thiel PLC       misc_pos  410.37   Ashley   \n",
       "90763        fraud_Kihn, Brakus and Goyette  personal_care   38.94    Stacy   \n",
       "90764                     fraud_Gerhold LLC           home   29.43     Tina   \n",
       "90765                      fraud_Stark-Batz  entertainment    3.49    Renee   \n",
       "90766  fraud_Streich, Rolfson and Wilderman      kids_pets  104.23    Renee   \n",
       "\n",
       "            last gender                        street              city  ...  \\\n",
       "0       Thompson      F            0362 Anderson Wall        Mound City  ...   \n",
       "1        Johnson      M           094 Owens Underpass           Norwalk  ...   \n",
       "2           Wise      F   674 Maureen Summit Apt. 276      Scotts Mills  ...   \n",
       "3        Everett      M               4138 David Fall        Morrisdale  ...   \n",
       "4           Hall      F               8851 Reese Neck             Basye  ...   \n",
       "...          ...    ...                           ...               ...  ...   \n",
       "90762       Cruz      F  65417 Walsh Radial Suite 691       Saint Amant  ...   \n",
       "90763   Villegas      F              20581 Pena Walks  Colorado Springs  ...   \n",
       "90764  Zimmerman      F   3595 Susan Island Suite 063            Thomas  ...   \n",
       "90765    Parrish      F  174 Jennifer Meadow Apt. 467     Mountain Park  ...   \n",
       "90766    Parrish      F  174 Jennifer Meadow Apt. 467     Mountain Park  ...   \n",
       "\n",
       "           long  city_pop                                 job         dob  \\\n",
       "0      -95.2138      1631                           Architect  1953-01-20   \n",
       "1     -118.0818    105549                         Firefighter  1973-09-22   \n",
       "2     -122.6187      1252                 Engineer, petroleum  1937-02-06   \n",
       "3      -78.2357      3688                       Advice worker  1973-05-27   \n",
       "4      -78.7776       863                    Engineer, mining  1972-08-09   \n",
       "...         ...       ...                                 ...         ...   \n",
       "90762  -90.8435     10076            Surveyor, rural practice  1977-12-16   \n",
       "90763 -104.6556    525713  Museum/gallery exhibitions officer  1992-05-09   \n",
       "90764  -98.7388      1675                           Barrister  1986-05-01   \n",
       "90765  -98.9591       540  Research scientist (life sciences)  1983-10-12   \n",
       "90766  -98.9591       540  Research scientist (life sciences)  1983-10-12   \n",
       "\n",
       "                              trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0      3d21bce7967838c3988cfe0f7fca878a  1336132624  41.024651  -94.428240   \n",
       "1      fda7712b4bbcaab36afded37ab55047f  1355475321  33.808771 -118.031888   \n",
       "2      59161e0002642934974c1ae98bfa1f55  1333084893  44.561034 -123.281803   \n",
       "3      f487a7098c0bd4d45f710be1745c4acb  1348038586  41.612825  -78.316893   \n",
       "4      c2ed76f03cce8a6b362729a5a23f01c2  1328387864  39.387521  -79.674956   \n",
       "...                                 ...         ...        ...         ...   \n",
       "90762  14b94dc8026970fae77db1deb747f35f  1336009855  30.152101  -90.420021   \n",
       "90763  f93f924d08a19064ec37de7a69cf8e4b  1364335428  38.648246 -104.969889   \n",
       "90764  12177fa4ce00fc361366c28e0af96b81  1329402054  35.110496  -98.246154   \n",
       "90765  4a248f9b8268ba53241625b4af2a271c  1340549594  35.135938  -98.112255   \n",
       "90766  9e73bbda29bc0568cbcf48975a2e1372  1340385699  34.624869  -99.008428   \n",
       "\n",
       "       is_fraud  merch_zipcode  \n",
       "0             0        50842.0  \n",
       "1             0        90630.0  \n",
       "2             0        97331.0  \n",
       "3             0        15834.0  \n",
       "4             0        26444.0  \n",
       "...         ...            ...  \n",
       "90762         0        70068.0  \n",
       "90763         0        80926.0  \n",
       "90764         0        73005.0  \n",
       "90765         0        73092.0  \n",
       "90766         0        73566.0  \n",
       "\n",
       "[90767 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('../data/01_raw/data_v1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c928ffa",
   "metadata": {},
   "source": [
    "## 3. Data Drift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "    '''Calculate the PSI (population stability index) across all variables\n",
    "    Args:\n",
    "       expected: numpy matrix of original values\n",
    "       actual: numpy matrix of new values, same size as expected\n",
    "       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
    "       buckets: number of quantiles to use in bucketing variables\n",
    "       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
    "    Returns:\n",
    "       psi_values: ndarray of psi values for each variable\n",
    "    Author:\n",
    "       Matthew Burke\n",
    "       github.com/mwburke\n",
    "       worksofchart.com\n",
    "    '''\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        '''Calculate the PSI for a single variable\n",
    "        Args:\n",
    "           expected_array: numpy array of original values\n",
    "           actual_array: numpy array of new values, same size as expected\n",
    "           buckets: number of percentile ranges to bucket the values into\n",
    "        Returns:\n",
    "           psi_value: calculated PSI value\n",
    "        '''\n",
    "        def scale_range(input, min_val, max_val):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max_val - min_val)\n",
    "            input += min_val\n",
    "            return input\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / buckets * 100\n",
    "\n",
    "        if buckettype == 'bins':\n",
    "            breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        elif buckettype == 'quantiles':\n",
    "            breakpoints = np.percentile(expected_array, breakpoints)\n",
    "\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            e_perc = max(e_perc, 0.0001)\n",
    "            a_perc = max(a_perc, 0.0001)\n",
    "            return (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "\n",
    "        psi_value = np.sum([sub_psi(expected_percents[i], actual_percents[i]) for i in range(len(expected_percents))])\n",
    "        return psi_value\n",
    "\n",
    "    # Fix initialization\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.array([psi(expected, actual, buckets)])\n",
    "    else:\n",
    "        psi_values = np.zeros(expected.shape[1] if axis == 0 else expected.shape[0])\n",
    "\n",
    "        for i in range(len(psi_values)):\n",
    "            if axis == 0:\n",
    "                psi_values[i] = psi(expected[:, i], actual[:, i], buckets)\n",
    "            elif axis == 1:\n",
    "                psi_values[i] = psi(expected[i, :], actual[i, :], buckets)\n",
    "\n",
    "    return psi_values\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e237fb31",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n",
    "    '''Calculate the PSI (population stability index) across all variables\n",
    "    Args:\n",
    "       expected: numpy matrix of original values\n",
    "       actual: numpy matrix of new values, same size as expected\n",
    "       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n",
    "       buckets: number of quantiles to use in bucketing variables\n",
    "       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n",
    "    Returns:\n",
    "       psi_values: ndarray of psi values for each variable\n",
    "    Author:\n",
    "       Matthew Burke\n",
    "       github.com/mwburke\n",
    "       worksofchart.com\n",
    "    '''\n",
    "\n",
    "    def psi(expected_array, actual_array, buckets):\n",
    "        '''Calculate the PSI for a single variable\n",
    "        Args:\n",
    "           expected_array: numpy array of original values\n",
    "           actual_array: numpy array of new values, same size as expected\n",
    "           buckets: number of percentile ranges to bucket the values into\n",
    "        Returns:\n",
    "           psi_value: calculated PSI value\n",
    "        '''\n",
    "\n",
    "        def scale_range (input, min, max):\n",
    "            input += -(np.min(input))\n",
    "            input /= np.max(input) / (max - min)\n",
    "            input += min\n",
    "            return input\n",
    "\n",
    "\n",
    "        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "\n",
    "        if buckettype == 'bins':\n",
    "            breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n",
    "        elif buckettype == 'quantiles':\n",
    "            breakpoints = np.stack([np.percentile(expected_array, b) for b in breakpoints])\n",
    "\n",
    "\n",
    "\n",
    "        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n",
    "        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n",
    "\n",
    "        def sub_psi(e_perc, a_perc):\n",
    "            '''Calculate the actual PSI value from comparing the values.\n",
    "               Update the actual value to a very small number if equal to zero\n",
    "            '''\n",
    "            if a_perc == 0:\n",
    "                a_perc = 0.0001\n",
    "            if e_perc == 0:\n",
    "                e_perc = 0.0001\n",
    "\n",
    "            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "            return(value)\n",
    "\n",
    "        psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n",
    "\n",
    "        return(psi_value)\n",
    "\n",
    "    if len(expected.shape) == 1:\n",
    "        psi_values = np.empty(len(expected.shape))\n",
    "    else:\n",
    "        psi_values = np.empty(expected.shape[axis])\n",
    "\n",
    "    for i in range(0, len(psi_values)):\n",
    "        if len(psi_values) == 1:\n",
    "            psi_values = psi(expected, actual, buckets)\n",
    "        elif axis == 0:\n",
    "            psi_values[i] = psi(expected[:,i], actual[:,i], buckets)\n",
    "        elif axis == 1:\n",
    "            psi_values[i] = psi(expected[i,:], actual[i,:], buckets)\n",
    "\n",
    "    return(psi_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2335c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_random(df):\n",
    "\n",
    "    ref_data = df.sample(frac=0.8,random_state=200)\n",
    "    ana_data = df.drop(ref_data.index)\n",
    "\n",
    "    return ref_data, ana_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525efab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data, ana_data = split_random(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447728f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSI Scores:\n",
      " amt           0.000428\n",
      "lat           0.000597\n",
      "long          0.001278\n",
      "city_pop      0.000425\n",
      "unix_time     0.000314\n",
      "merch_lat     0.000646\n",
      "merch_long    0.000935\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Pick numeric columns\n",
    "numeric_cols = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long']\n",
    "\n",
    "psi_scores = calculate_psi(\n",
    "    expected=ref_data[numeric_cols].values,\n",
    "    actual=ana_data[numeric_cols].values,\n",
    "    buckettype='quantiles',  # or 'bins'\n",
    "    buckets=10,\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "# Pair scores with column names\n",
    "psi_results = pd.Series(psi_scores, index=numeric_cols)\n",
    "print(\"PSI Scores:\\n\", psi_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1128c4f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _smoothers_lowess: The filename or extension is too long.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnml\u001b[39;00m\n\u001b[32m      3\u001b[39m categorical_cols = [\u001b[33m'\u001b[39m\u001b[33mjob\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgender\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m chunk_size = \u001b[32m50\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\nannyml\\__init__.py:44\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcalibration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Calibrator, IsotonicCalibrator, needs_calibration\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchunk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chunk, Chunker, CountBasedChunker, DefaultChunker, PeriodBasedChunker, SizeBasedChunker\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_quality\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MissingValuesCalculator, NumericalRangeCalculator, UnseenValuesCalculator\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     46\u001b[39m     load_modified_california_housing_dataset,\n\u001b[32m     47\u001b[39m     load_synthetic_binary_classification_dataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m     53\u001b[39m     load_us_census_ma_employment_data,\n\u001b[32m     54\u001b[39m )\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CategoricalDistributionCalculator, ContinuousDistributionCalculator\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\nannyml\\data_quality\\__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#  Author:   Niels Nuyttens  <niels@nannyml.com>\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#  Author:   Nikolaos Perrakis  <nikos@nannyml.com>\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#  License: Apache Software License 2.0\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"Package containing the Data Quality Calculators implementation.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MissingValuesCalculator\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01munseen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UnseenValuesCalculator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrange\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumericalRangeCalculator\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\nannyml\\data_quality\\missing\\__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#  Author:   Niels Nuyttens  <niels@nannyml.com>\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#  Author:   Nikolaos Perrakis  <nikos@nannyml.com>\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#  License: Apache Software License 2.0\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"Package containing the Data Quality Calculators implementation.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcalculator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MissingValuesCalculator\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresult\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\nannyml\\data_quality\\missing\\calculator.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiIndex\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AbstractCalculator, _list_missing\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchunk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chunker\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InvalidArgumentsException\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\nannyml\\base.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_objects\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Key, Metric, Result, Self\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchunk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chunker, ChunkerFactory\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CalculatorException, EstimatorException, InvalidArgumentsException, NannyMLException\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\nannyml\\_typing.py:30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InvalidArgumentsException\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Figure\n\u001b[32m     32\u001b[39m Key = namedtuple(\u001b[33m'\u001b[39m\u001b[33mKey\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mproperties display_names\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mResult\u001b[39;00m(Protocol):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\nannyml\\plots\\__init__.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"Module containing plotting implementations.\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplots\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Colors\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplots\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcomponents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfigure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Figure  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplots\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcomponents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhover\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     Hover,\n\u001b[32m     15\u001b[39m     render_alert_string,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     render_x_coordinate,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplots\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcomponents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjoy_plot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m calculate_chunk_distributions, joy\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\nannyml\\plots\\components\\__init__.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfigure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Figure\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhover\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hover, render_alert_string, render_partial_target_string, render_period_string, render_x_coordinate\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjoy_plot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m calculate_chunk_distributions\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstacked_bar_plot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m calculate_value_counts\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\nannyml\\plots\\components\\joy_plot.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgo\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cumulative_trapezoid\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m sm\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchunk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chunker\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnannyml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplots\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Colors\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\statsmodels\\api.py:123\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenmod\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m genmod\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenmod\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    114\u001b[39m     GEE,\n\u001b[32m    115\u001b[39m     GLM,\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m     families,\n\u001b[32m    122\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraphics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api \u001b[38;5;28;01mas\u001b[39;00m graphics\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraphics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgofplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProbPlot, qqline, qqplot, qqplot_2samples\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimputation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbayes_mi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MI, BayesGaussMI\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\statsmodels\\graphics\\api.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgofplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m qqplot\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplottools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rainbow\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregressionplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     abline_plot,\n\u001b[32m     11\u001b[39m     influence_plot,\n\u001b[32m     12\u001b[39m     plot_ccpr,\n\u001b[32m     13\u001b[39m     plot_ccpr_grid,\n\u001b[32m     14\u001b[39m     plot_fit,\n\u001b[32m     15\u001b[39m     plot_leverage_resid2,\n\u001b[32m     16\u001b[39m     plot_partregress,\n\u001b[32m     17\u001b[39m     plot_partregress_grid,\n\u001b[32m     18\u001b[39m     plot_regress_exog,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m __all__ = [\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mabline_plot\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbeanplot\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mviolinplot\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     43\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\statsmodels\\graphics\\regressionplots.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenmod\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneralized_linear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GLM\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraphics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnonparametric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msmoothers_lowess\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lowess\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregression\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GLS, OLS, WLS\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msandbox\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregression\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpredstd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wls_prediction_std\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danie\\Downloads\\NOVA IMS\\Masters - Data Science and Advanced Analytics\\1st year\\2nd semester\\Machine Learning Operations\\machine-learning-operations-project-2\\venv\\Lib\\site-packages\\statsmodels\\nonparametric\\smoothers_lowess.py:10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Lowess - wrapper for cythonized extension\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mAuthor : Chris Jordan-Squire\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smoothers_lowess\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lowess \u001b[38;5;28;01mas\u001b[39;00m _lowess\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlowess\u001b[39m(endog, exog, frac=\u001b[32m2.0\u001b[39m/\u001b[32m3.0\u001b[39m, it=\u001b[32m3\u001b[39m, delta=\u001b[32m0.0\u001b[39m, xvals=\u001b[38;5;28;01mNone\u001b[39;00m, is_sorted=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     13\u001b[39m            missing=\u001b[33m'\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m'\u001b[39m, return_sorted=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     14\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''LOWESS (Locally Weighted Scatterplot Smoothing)\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[33;03m    A lowess function that outs smoothed estimates of endog\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m \n\u001b[32m    135\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _smoothers_lowess: The filename or extension is too long."
     ]
    }
   ],
   "source": [
    "import nannyml as nml\n",
    "\n",
    "categorical_cols = ['job', 'category', 'gender']\n",
    "chunk_size = 50\n",
    "\n",
    "# Set thresholds (optional - adjust the threshold value if needed)\n",
    "threshold = nml.thresholds.ConstantThreshold(lower=None, upper=0.2)\n",
    "\n",
    "calc = nml.UnivariateDriftCalculator(\n",
    "    column_names=categorical_cols,\n",
    "    treat_as_categorical=categorical_cols,\n",
    "    chunk_size=chunk_size,\n",
    "    categorical_methods=['jensen_shannon'],\n",
    "    thresholds={\"jensen_shannon\": threshold}\n",
    ")\n",
    "\n",
    "calc.fit(ref_data)\n",
    "result = calc.calculate(ana_data)\n",
    "drift_df = result.filter(period='analysis').to_df()\n",
    "\n",
    "# Save plot\n",
    "plot = result.filter(period='analysis').plot(kind='drift')\n",
    "plot.write_html(\"univariate_drift_nml.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e12fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uv pip install evidently\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "report = Report(metrics=[\n",
    "    DataDriftPreset()\n",
    "])\n",
    "\n",
    "report.run(\n",
    "    reference_data=ref_data,\n",
    "    current_data=ana_data,\n",
    "    column_mapping=None\n",
    ")\n",
    "\n",
    "report.save_html(\"data_drift_evidently.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa7c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(ref_data)):\n",
    "    ref_fold = ref_data.iloc[train_idx]\n",
    "    ana_fold = ref_data.iloc[test_idx]\n",
    "\n",
    "    psi_scores = calculate_psi(ref_fold[numeric_cols].values, ana_fold[numeric_cols].values)\n",
    "    print(f\"Fold {i+1} PSI:\\n\", pd.Series(psi_scores, index=numeric_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ref_scaled = scaler.fit_transform(ref_data[numeric_cols])\n",
    "ana_scaled = scaler.transform(ana_data[numeric_cols])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "ref_pca = pca.fit_transform(ref_scaled)\n",
    "ana_pca = pca.transform(ana_scaled)\n",
    "\n",
    "# Use PSI on PCA features\n",
    "psi_pca = calculate_psi(ref_pca, ana_pca)\n",
    "print(\"PSI on PCA Components:\", psi_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
